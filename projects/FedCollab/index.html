<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body>
<h1 id="optimizing-the-collaboration-structure-in-cross-silo-federated-learning">Optimizing the Collaboration Structure in Cross-Silo Federated Learning</h1>

<p><a href="https://baowenxuan.github.io/">Wenxuan Bao</a>, 
<a href="https://haohanwang.github.io/" rel="external nofollow noopener" target="_blank">Haohan Wang</a>, 
<a href="https://publish.illinois.edu/junwu3/" rel="external nofollow noopener" target="_blank">Jun Wu</a>, 
<a href="https://www.hejingrui.org/" rel="external nofollow noopener" target="_blank">Jingrui He</a></p>

<p>[<a href="https://arxiv.org/abs/2306.06508" rel="external nofollow noopener" target="_blank">arxiv</a>] [poster] [slides] [talk] [code] [bibtex]</p>

<p>We propose FedCollab to alleviate the negative transfer problem in federated learning by clustering clients into non-overlapping coalitions based on their distribution distances and data quantities.</p>

<ul>
  <li>Theory: We analyze how clustered FL performance is affected by two key factors: distribution distance and data quantity.</li>
  <li>Algorithm: We propose FedCollab to solve for the best collaboration structure.</li>
  <li>Extensive experiments: We test FedCollab under label shift, feature shift and concept shift with various models / datasets.</li>
</ul>

<h2 id="abstract">Abstract</h2>

<p>In federated learning (FL), multiple clients collaborate to train machine learning models together while keeping their data decentralized. Through utilizing more training data, FL suffers from the potential negative transfer problem: the global FL model may even perform worse than the models trained with local data only. In this paper, we propose FedCollab, a novel FL framework that alleviates negative transfer by clustering clients into non-overlapping coalitions based on their distribution distances and data quantities. As a result, each client only collaborates with the clients having similar data distributions, and tends to collaborate with more clients when it has less data. We evaluate our framework with a variety of datasets, models, and types of non-IIDness. Our results demonstrate that FedCollab effectively mitigates negative transfer across a wide range of FL algorithms and consistently outperforms other clustered FL algorithms.</p>

<h2 id="introduction">Introduction</h2>

<p>We consider a FL system with $N$ clients $1, \cdots, N$ connected to a central server.</p>

<h2 id="method">Method</h2>

<h2 id="result">Result</h2>

<p>We conduct</p>

<h2 id="acknowledgements">Acknowledgements</h2>

</body></html>
